### Hi there ğŸ‘‹
(Here is my [ğŸª knowledge planet](https://publish.obsidian.md/yuyangzhang/Home))


# Paper Replicate:
- ğŸ”´ [Attentions from scratch](https://github.com/JAZ201107/DL-Experiments/blob/main/understand-and-visualize-attention-mechanism.ipynb)
  - ğŸŸ¢ [Image Caption with Bahdanau Attention](https://github.com/JAZ201107/DL-Experiments/blob/main/image-caption-with-attention-flicker8k.ipynb)
  - ğŸ”´ [Image Caption with Transformer Decoder]
- ğŸ”´ [Transformer from scratch]()
- ğŸ”´ [Vision Transformer from scratch](https://github.com/JAZ201107/DL-Experiments/blob/main/build-classic-cnn-and-vit-from-scratch.ipynb)
- ğŸ”´ [BERT from scratch]()
- ğŸ”´ [GPT from scratch]()
- ğŸ”´ [CLIP from scratch](https://github.com/JAZ201107/DL-Experiments/blob/main/CLIP_from_scratch.ipynb)
- ğŸ”´ Byte-pair encoding from scratch


# Computer Vision:
* ğŸŸ¢ [Image Classification](https://github.com/JAZ201107/Image-Classification)
* ğŸ”´ Image Super Resolution
* ğŸ”´ Object Detection

# Natural Language Processing
* ğŸ”´ [Text Classification]()
* ğŸ”´ [Machine Translation]()
* ğŸ”´ Sequence Labeling


# Multi Model
* ğŸŸ¢ [Image Caption](https://github.com/JAZ201107/Image-Caption)
  

# Un-supervised Learning
* ğŸ”´ Autoencoder for CIFAR-10
* ğŸ”´ SimCLR for CIFAR-10
* ğŸ”´ SupCon* for CIFAR-10
